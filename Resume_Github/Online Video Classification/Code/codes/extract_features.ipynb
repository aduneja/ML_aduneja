{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"extract_features.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"6bvvzl2QXooj","colab_type":"code","outputId":"fa03e998-566f-48af-93cb-b95c8016e8d1","executionInfo":{"status":"ok","timestamp":1556912376044,"user_tz":240,"elapsed":5713,"user":{"displayName":"Dnyanada Joshi","photoUrl":"","userId":"02127425908554612822"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LUFArngzXokJ","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import img_to_array, load_img\n","from keras.preprocessing import image as IMAGE\n","from keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from keras.models import Model, load_model\n","from keras.layers import Input\n","\n","import numpy as np\n","import os.path\n","from tqdm import tqdm\n","import csv\n","import os\n","import glob"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUXS_A6rXoWw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VhZiHx5SXoRS","colab_type":"code","colab":{}},"source":["class Extractor():\n","    def __init__(self, weights=None):\n","        \"\"\"Either load pretrained from imagenet, or load our saved\n","        weights from our own training.\"\"\"\n","\n","        self.weights = weights  \n","\n","        if weights is None:\n","            # Get model with pretrained weights.\n","            base_model = InceptionV3(\n","                weights='imagenet',\n","                include_top=True\n","            )\n","\n","            # We'll extract features at the final pool layer.\n","            self.model = Model(\n","                inputs=base_model.input,\n","                outputs=base_model.get_layer('avg_pool').output\n","            )\n","\n","        else:\n","            # Load the model first.\n","            self.model = load_model(weights)\n","\n","            # Then remove the top so we get features not predictions.\n","            # From: https://github.com/fchollet/keras/issues/2371\n","            self.model.layers.pop()\n","            self.model.layers.pop()  # two pops to get to pool layer\n","            self.model.outputs = [self.model.layers[-1].output]\n","            self.model.output_layers = [self.model.layers[-1]]\n","            self.model.layers[-1].outbound_nodes = []\n","\n","    def extract(self, image_path):\n","        img = IMAGE.load_img(image_path, target_size=(299, 299))\n","        x = IMAGE.img_to_array(img)\n","        x = np.expand_dims(x, axis=0)\n","        x = preprocess_input(x)\n","\n","        # Get the prediction.\n","        features = self.model.predict(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pCGcjH7dXoIE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4lJBaiPXoEC","colab_type":"code","colab":{}},"source":["class threadsafe_iterator:\n","    def __init__(self, iterator):\n","        self.iterator = iterator\n","        self.lock = threading.Lock()\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        with self.lock:\n","            return next(self.iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBM7IEoKXoCr","colab_type":"code","colab":{}},"source":["def threadsafe_generator(func):\n","    \"\"\"Decorator\"\"\"\n","    def gen(*a, **kw):\n","        return threadsafe_iterator(func(*a, **kw))\n","    return gen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"azMZJ-9RYXTP","colab_type":"code","colab":{}},"source":["class DataSet():\n","\n","    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n","        \"\"\"Constructor.\n","        seq_length = (int) the number of frames to consider\n","        class_limit = (int) number of classes to limit the data to.\n","            None = no limit.\n","        \"\"\"\n","        self.seq_length = seq_length\n","        self.class_limit = class_limit\n","        self.sequence_path = os.path.join('gdrive/My Drive/ADBI_Capstone_Video_Classification/data/', 'features')\n","        #change above line\n","        self.max_frames = 300  # max number of frames a video can have for us to use it\n","        self.image_shape = image_shape\n","\n","        # Get the data.\n","        data = []\n","        with open(os.path.join('gdrive/My Drive/ADBI_Capstone_Video_Classification/data/', 'data_file.csv'), 'r') as fin:\n","            reader = csv.reader(fin)\n","            data = list(reader)\n","\n","        self.data = [x for x in data if x != []]\n","        self.classes = self.get_classes(self)\n","        #Clean up the data\n","        data = []\n","        for item in self.data:\n","            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n","                    and item[1] in self.classes:\n","                    data.append(item)\n","\n","        self.data = data\n","        \n","    @staticmethod\n","    def get_classes(self):\n","        \"\"\"Extract the classes from the data\"\"\"\n","        classes = []\n","        for item in self.data:\n","            if item[1] not in classes:\n","                classes.append(item[1])\n","\n","        classes = sorted(classes)\n","\n","        \"\"\" Return only a few classes if a limit is defined\"\"\"\n","        if self.class_limit is not None:\n","            return classes[:self.class_limit]\n","        else:\n","            return classes\n","\n","    \n","    @staticmethod\n","    def get_frames_for_sample(sample):\n","        \"\"\"Given a sample row from the data file, get all the corresponding frame\n","        filenames.\"\"\"\n","        path = os.path.join('gdrive/My Drive/ADBI_Capstone_Video_Classification/data/', sample[0], sample[1])\n","        filename = sample[2]\n","        images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n","        return images\n","\n","\n","    @staticmethod\n","    def rescale_list(input_list, size):\n","        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n","        if we want a list of size 5 and we have a list of size 25, return a new\n","        list of size five which is every 5th element of the origina list.\"\"\"\n","        assert len(input_list) >= size\n","\n","        # Get the number to skip between iterations.\n","        skip = len(input_list) // size\n","\n","        # Build our new output.\n","        output = [input_list[i] for i in range(0, len(input_list), skip)]\n","\n","        # Cut off the last one if needed.\n","        return output[:size]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"49OXEnSWZAU7","colab_type":"code","outputId":"610c7aa3-a689-4b63-ad43-ff3bb227b44b","executionInfo":{"status":"ok","timestamp":1556912404124,"user_tz":240,"elapsed":33499,"user":{"displayName":"Dnyanada Joshi","photoUrl":"","userId":"02127425908554612822"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["seq_length = 40\n","class_limit = None  # Number of classes to extract. Can be 1-101 or None for all.\n","\n","# Get the dataset.\n","data = DataSet(seq_length=seq_length, class_limit=class_limit)\n","# get the model.\n","model = Extractor()\n","\n","# Loop through data.\n","pbar = tqdm(total=len(data.data))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","\n","\n","  0%|          | 0/12014 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"myVHJKbsYXRg","colab_type":"code","colab":{}},"source":["for video in data.data:\n","    \n","    print(video)\n","    # Get the path to the sequence for this video.\n","    path = os.path.join('gdrive/My Drive/ADBI_Capstone_Video_Classification/data/', 'features', video[2] + '-' + str(seq_length) + \\\n","        '-features')  # numpy will auto-append .npy\n","\n","    # Check if we already have it.\n","    if os.path.isfile(path + '.npy'):\n","        pbar.update(1)\n","        continue\n","\n","    # Get the frames for this video.\n","    frames = data.get_frames_for_sample(video)\n","\n","    # Now downsample to just the ones we need.\n","    #frames = data.rescale_list(frames, seq_length)\n","\n","    # Now loop through and extract features to build the sequence.\n","    sequence = []\n","    for f in frames:\n","        features = model.extract(f)\n","        sequence.append(features)\n","\n","    # Save the sequence.\n","    np.save(path, sequence)\n","\n","    pbar.update(1)\n","    \n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UeSmrdFJYXBU","colab_type":"code","colab":{}},"source":["pbar.close()"],"execution_count":0,"outputs":[]}]}