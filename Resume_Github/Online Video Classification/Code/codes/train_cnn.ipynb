{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_cnn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"71kr5oC-UaQg","colab_type":"code","outputId":"293c3745-9af2-445d-8ca2-1b665484acf9","executionInfo":{"status":"ok","timestamp":1556909552527,"user_tz":240,"elapsed":7127,"user":{"displayName":"Mrunmayi Deshpande","photoUrl":"https://lh4.googleusercontent.com/-GuZx90EJBgg/AAAAAAAAAAI/AAAAAAAAAAc/9_0xwaB9wTE/s64/photo.jpg","userId":"06161468905840108367"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NgkOfOdwTqPN","colab_type":"code","outputId":"7094145f-f4bd-4485-b6de-19115fe94f46","executionInfo":{"status":"ok","timestamp":1556909556666,"user_tz":240,"elapsed":1351,"user":{"displayName":"Mrunmayi Deshpande","photoUrl":"https://lh4.googleusercontent.com/-GuZx90EJBgg/AAAAAAAAAAI/AAAAAAAAAAc/9_0xwaB9wTE/s64/photo.jpg","userId":"06161468905840108367"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.applications.inception_v3 import InceptionV3\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, CSVLogger\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import img_to_array, load_img\n","\n","import csv\n","import numpy as np\n","import random\n","import glob\n","import sys\n","import operator\n","import threading\n","import os.path\n","import time"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YNa9RdlPUrvr","colab_type":"code","colab":{}},"source":["def process_image(image, target_shape):\n","    \"\"\"Given an image, process it and return the array.\"\"\"\n","    # Load the image.\n","    h, w, _ = target_shape\n","    image = load_img(image, target_size=(h, w))\n","\n","    # Turn it into numpy, normalize and return.\n","    img_arr = img_to_array(image)\n","    x = (img_arr / 255.).astype(np.float32)\n","\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t1_559azUrzS","colab_type":"code","colab":{}},"source":["class threadsafe_iterator:\n","    def __init__(self, iterator):\n","        self.iterator = iterator\n","        self.lock = threading.Lock()\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        with self.lock:\n","            return next(self.iterator)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"glN_f6wJUr-T","colab_type":"code","colab":{}},"source":["def threadsafe_generator(func):\n","    \"\"\"Decorator\"\"\"\n","    def gen(*a, **kw):\n","        return threadsafe_iterator(func(*a, **kw))\n","    return gen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_7X1Lj_UsC7","colab_type":"code","colab":{}},"source":["class DataSet():\n","\n","    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n","        \"\"\"Constructor.\n","        seq_length = (int) the number of frames to consider\n","        class_limit = (int) number of classes to limit the data to.\n","            None = no limit.\n","        \"\"\"\n","        self.seq_length = seq_length\n","        self.class_limit = class_limit\n","        self.sequence_path = os.path.join(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/\", 'features')\n","        #change above line\n","        self.max_frames = 300  # max number of frames a video can have for us to use it\n","\n","        # Get the data.\n","        self.data = self.get_data()\n","\n","        # Get the classes.\n","        self.classes = self.get_classes()\n","\n","        # Now do some minor data cleaning.\n","        self.data = self.clean_data()\n","\n","        self.image_shape = image_shape\n","\n","    @staticmethod\n","    def get_data():\n","        \"\"\"Load our data from file.\"\"\"\n","        #change below line\n","        with open(os.path.join(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/\", 'data_file.csv'), 'r') as fin:\n","            reader = csv.reader(fin)\n","            data = list(reader)\n","\n","        data = [x for x in data if x != []]\n","        return data\n","\n","    def clean_data(self):\n","        \"\"\"Limit samples to greater than the sequence length and fewer\n","        than N frames. Also limit it to classes we want to use.\"\"\"\n","        data_clean = []\n","        for item in self.data:\n","            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n","                    and item[1] in self.classes:\n","                data_clean.append(item)\n","\n","        return data_clean\n","\n","    def get_classes(self):\n","        \"\"\"Extract the classes from our data. If we want to limit them,\n","        only return the classes we need.\"\"\"\n","        classes = []\n","        for item in self.data:\n","            if item[1] not in classes:\n","                classes.append(item[1])\n","\n","        # Sort them.\n","        classes = sorted(classes)\n","\n","        # Return.\n","        if self.class_limit is not None:\n","            return classes[:self.class_limit]\n","        else:\n","            return classes\n","    \n","    \n","    def get_class_one_hot(self, class_str):\n","        \"\"\"Given a class as a string, return its number in the classes\n","        list. This lets us encode and one-hot it for training.\"\"\"\n","        # Encode it first.\n","        label_encoded = self.classes.index(class_str)\n","\n","        # Now one-hot it.\n","        label_hot = to_categorical(label_encoded, len(self.classes))\n","\n","        assert len(label_hot) == len(self.classes)\n","\n","        return label_hot\n","    \n","    \n","    def get_extracted_sequence(self, data_type, sample):\n","        \"\"\"Get the saved extracted features.\"\"\"\n","        filename = sample[2]\n","        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n","            '-' + data_type + '.npy')\n","        if os.path.isfile(path):\n","            return np.load(path)\n","        else:\n","            print(\"file path: \", path)\n","            return None\n","          \n","    \n","    \n","    def split_train_test(self):\n","        \"\"\"Split the data into train and test groups.\"\"\"\n","        train = []\n","        test = []\n","        for item in self.data:\n","            if item[0] == 'train':\n","                train.append(item)\n","            else:\n","                test.append(item)\n","        return train, test\n","    \n","    \n","    @threadsafe_generator\n","    def frame_generator(self, batch_size, train_test, data_type):\n","      \"\"\"Return a generator that we can use to train on. There are\n","      a couple different things we can return:\n","      data_type: 'features', 'images'\n","      \"\"\"\n","      # Get the right dataset for the generator.\n","      train, test = self.split_train_test()\n","      data = train if train_test == 'train' else test\n","\n","      print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n","\n","      while 1:\n","          X, y = [], []\n","\n","          # Generate batch_size samples.\n","          for _ in range(batch_size):\n","              # Reset to be safe.\n","              sequence = None\n","\n","              # Get a random sample.\n","              sample = random.choice(data)\n","\n","              # Check to see if we've already saved this sequence.\n","              if data_type is \"images\":\n","                  # Get and resample frames.\n","                  frames = self.get_frames_for_sample(sample)\n","                  frames = self.rescale_list(frames, self.seq_length)\n","\n","                  # Build the image sequence\n","                  sequence = self.build_image_sequence(frames)\n","              else:\n","                  # Get the sequence from disk.\n","                  sequence = self.get_extracted_sequence(data_type, sample)\n","\n","                  if sequence is None:\n","                      raise ValueError(\"Can't find sequence. Did you generate them?\")\n","\n","                  X.append(sequence)\n","                  y.append(self.get_class_one_hot(sample[1]))\n","\n","              yield np.array(X), np.array(y)\n","          "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RXKFaT7Ur7w","colab_type":"code","colab":{}},"source":["data = DataSet()\n","\n","checkpointer = ModelCheckpoint(\n","    filepath=\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/models/inception.{epoch:03d}-{val_loss:.2f}.hdf5\",\n","    verbose=1,\n","    save_best_only=True)\n","\n","\n","early_stopper = EarlyStopping(patience=10)\n","\n","\n","tensorboard = TensorBoard(log_dir=os.path.join('data', 'meta'))\n","\n","timestamp = time.time()\n","csv_logger = CSVLogger(os.path.join(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/\" , 'meta', 'cnn' + '-' + 'training-' + \\\n","        str(timestamp) + '.log'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MV61Xbm7Ur5X","colab_type":"code","colab":{}},"source":["def get_generators():\n","    train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        horizontal_flip=True,\n","        rotation_range=10.,\n","        width_shift_range=0.2,\n","        height_shift_range=0.2)\n","\n","    test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    train_generator = train_datagen.flow_from_directory(\n","        os.path.join(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/\", \"train\"),\n","        target_size=(299, 299),\n","        batch_size=16,\n","        classes=data.classes,\n","        class_mode='categorical')\n","\n","    validation_generator = test_datagen.flow_from_directory(\n","         os.path.join(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/\",  'test'),\n","        target_size=(299, 299),\n","        batch_size=16,\n","        classes=data.classes,\n","        class_mode='categorical')\n","\n","    return train_generator, validation_generator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tpy2km8EUr3H","colab_type":"code","colab":{}},"source":["def get_model(weights='imagenet'):\n","    # create the base pre-trained model\n","    base_model = InceptionV3(weights=weights, include_top=False)\n","\n","    # add a global spatial average pooling layer\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    # let's add a fully-connected layer\n","    x = Dense(1024, activation='relu')(x)\n","    # and a logistic layer\n","    predictions = Dense(len(data.classes), activation='softmax')(x)\n","\n","    # this is the model we will train\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCsxhZQUWCnR","colab_type":"code","colab":{}},"source":["def freeze_all_but_top(model):\n","    \"\"\"Used to train just the top layers of the model.\"\"\"\n","    # first: train only the top layers (which were randomly initialized)\n","    # i.e. freeze all convolutional InceptionV3 layers\n","    for layer in model.layers[:-2]:\n","        layer.trainable = False\n","\n","    # compile the model (should be done *after* setting layers to non-trainable)\n","    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TzD_2QNWClO","colab_type":"code","colab":{}},"source":["def freeze_all_but_mid_and_top(model):\n","    \"\"\"After we fine-tune the dense layers, train deeper.\"\"\"\n","    # we chose to train the top 2 inception blocks, i.e. we will freeze\n","    # the first 172 layers and unfreeze the rest:\n","    for layer in model.layers[:172]:\n","        layer.trainable = False\n","    for layer in model.layers[172:]:\n","        layer.trainable = True\n","\n","    # we need to recompile the model for these modifications to take effect\n","    # we use SGD with a low learning rate\n","    model.compile(\n","        optimizer=SGD(lr=0.0001, momentum=0.9),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy', 'top_k_categorical_accuracy'])\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RJLILcEiWChz","colab_type":"code","colab":{}},"source":["def train_model(model, nb_epoch, generators, callbacks=[tensorboard, early_stopper,  csv_logger, checkpointer]):\n","    train_generator, validation_generator = generators\n","    model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=100,\n","        validation_data=validation_generator,\n","        validation_steps=10,\n","        epochs=nb_epoch,\n","        callbacks=[tensorboard, early_stopper,  csv_logger, checkpointer])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CN94BQigWCfK","colab_type":"code","colab":{}},"source":["def main(weights_file):\n","    model = get_model()\n","    generators = get_generators()\n","\n","    if weights_file is None:\n","        print(\"Loading network from ImageNet weights.\")\n","        # Get and train the top layers.\n","        model = freeze_all_but_top(model)\n","        model = train_model(model, 10, generators, [tensorboard, early_stopper,  csv_logger, checkpointer])\n","        #change epochs to 10\n","    else:\n","        print(\"Loading saved model: %s.\" % weights_file)\n","        model.load_weights(weights_file)\n","\n","    # Get and train the mid layers.\n","    model = freeze_all_but_mid_and_top(model)\n","    model = train_model(model, 10, generators,\n","                        [tensorboard, early_stopper,  csv_logger, checkpointer])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G27b8HOKWCco","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    weights_file = None\n","    main(weights_file)"],"execution_count":0,"outputs":[]}]}