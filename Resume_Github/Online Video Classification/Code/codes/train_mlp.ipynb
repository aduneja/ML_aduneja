{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_mlp.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"oClFfKzwGHDI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":126},"outputId":"2ceb0d55-06c7-48ea-ddf2-2d15bd3434e2","executionInfo":{"status":"ok","timestamp":1556901277001,"user_tz":240,"elapsed":26882,"user":{"displayName":"Mrunmayi Deshpande","photoUrl":"https://lh4.googleusercontent.com/-GuZx90EJBgg/AAAAAAAAAAI/AAAAAAAAAAc/9_0xwaB9wTE/s64/photo.jpg","userId":"06161468905840108367"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_rLW50RaGNH_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e9d88cd5-9e38-4342-cb7a-30cf7a676a17","executionInfo":{"status":"ok","timestamp":1556901281479,"user_tz":240,"elapsed":1488,"user":{"displayName":"Mrunmayi Deshpande","photoUrl":"https://lh4.googleusercontent.com/-GuZx90EJBgg/AAAAAAAAAAI/AAAAAAAAAAc/9_0xwaB9wTE/s64/photo.jpg","userId":"06161468905840108367"}}},"source":["from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n","from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n","from keras.layers import LSTM\n","from keras.models import Sequential, load_model\n","from keras.optimizers import Adam, RMSprop\n","from keras.layers import (Conv2D, MaxPooling3D, Conv3D, MaxPooling2D)\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import img_to_array, load_img\n","from collections import deque\n","import csv\n","import numpy as np\n","import random\n","import glob\n","import os.path\n","import sys\n","import operator\n","import threading\n","import sys\n","import time\n","import os.path"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"e4qRZJTYGNME","colab_type":"code","colab":{}},"source":["def process_image(image, target_shape):\n","    \"\"\"Given an image, process it and return the array.\"\"\"\n","    # Load the image.\n","    h, w, _ = target_shape\n","    image = load_img(image, target_size=(h, w))\n","\n","    # Turn it into numpy, normalize and return.\n","    img_arr = img_to_array(image)\n","    x = (img_arr / 255.).astype(np.float32)\n","\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKhdOJdsuUvM","colab_type":"code","colab":{}},"source":["class threadsafe_iterator:\n","    def __init__(self, iterator):\n","        self.iterator = iterator\n","        self.lock = threading.Lock()\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        with self.lock:\n","            return next(self.iterator)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nzZ6BsZ4uc6w","colab_type":"code","colab":{}},"source":["def threadsafe_generator(func):\n","    \"\"\"Decorator\"\"\"\n","    def gen(*a, **kw):\n","        return threadsafe_iterator(func(*a, **kw))\n","    return gen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hf5P01Z7GNQm","colab_type":"code","colab":{}},"source":["class DataSet():\n","\n","    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n","        \"\"\"Constructor.\n","        seq_length = (int) the number of frames to consider\n","        class_limit = (int) number of classes to limit the data to.\n","            None = no limit.\n","        \"\"\"\n","        self.seq_length = seq_length\n","        self.class_limit = class_limit\n","        self.sequence_path = \"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/features/\"\n","        \n","        self.max_frames = 300  # max number of frames a video can have for us to use it\n","\n","        # Get the data.\n","        self.data = self.get_data()\n","\n","        # Get the classes.\n","        self.classes = self.get_classes()\n","\n","        # Now do some minor data cleaning.\n","        self.data = self.clean_data()\n","\n","        self.image_shape = image_shape\n","\n","    @staticmethod\n","    def get_data():\n","        \"\"\"Load our data from file.\"\"\"\n","        #change below line\n","        with open(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/data_file.csv\", 'r') as fin:\n","            reader = csv.reader(fin)\n","            data = list(reader)\n","\n","        data = [x for x in data if x != []]\n","        return data\n","\n","    def clean_data(self):\n","        \"\"\"Limit samples to greater than the sequence length and fewer\n","        than N frames. Also limit it to classes we want to use.\"\"\"\n","        data_clean = []\n","        for item in self.data:\n","            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n","                    and item[1] in self.classes:\n","                data_clean.append(item)\n","\n","        return data_clean\n","\n","    def get_classes(self):\n","        \"\"\"Extract the classes from our data. If we want to limit them,\n","        only return the classes we need.\"\"\"\n","        classes = []\n","        for item in self.data:\n","            if item[1] not in classes:\n","                classes.append(item[1])\n","\n","        # Sort them.\n","        classes = sorted(classes)\n","\n","        # Return.\n","        if self.class_limit is not None:\n","            return classes[:self.class_limit]\n","        else:\n","            return classes\n","    \n","    \n","    def get_class_one_hot(self, class_str):\n","        \"\"\"Given a class as a string, return its number in the classes\n","        list. This lets us encode and one-hot it for training.\"\"\"\n","        # Encode it first.\n","        label_encoded = self.classes.index(class_str)\n","\n","        # Now one-hot it.\n","        label_hot = to_categorical(label_encoded, len(self.classes))\n","\n","        assert len(label_hot) == len(self.classes)\n","\n","        return label_hot\n","    \n","    \n","    def get_extracted_sequence(self, data_type, sample):\n","        \"\"\"Get the saved extracted features.\"\"\"\n","        filename = sample[2]\n","        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n","            '-' + data_type + '.npy')\n","        if os.path.isfile(path):\n","            return np.load(path)\n","        else:\n","            print(\"file path: \", path)\n","            return None\n","          \n","    \n","    \n","    def split_train_test(self):\n","        \"\"\"Split the data into train and test groups.\"\"\"\n","        train = []\n","        test = []\n","        for item in self.data:\n","            if item[0] == 'train':\n","                train.append(item)\n","            else:\n","                test.append(item)\n","        return train, test\n","    \n","    \n","    @threadsafe_generator\n","    def frame_generator(self, batch_size, train_test, data_type):\n","      \"\"\"Return a generator that we can use to train on. There are\n","      a couple different things we can return:\n","      data_type: 'features', 'images'\n","      \"\"\"\n","      # Get the right dataset for the generator.\n","      train, test = self.split_train_test()\n","      data = train if train_test == 'train' else test\n","\n","      print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n","\n","      while 1:\n","          X, y = [], []\n","\n","          # Generate batch_size samples.\n","          for _ in range(batch_size):\n","              # Reset to be safe.\n","              sequence = None\n","\n","              # Get a random sample.\n","              sample = random.choice(data)\n","\n","              # Check to see if we've already saved this sequence.\n","              if data_type is \"images\":\n","                  # Get and resample frames.\n","                  frames = self.get_frames_for_sample(sample)\n","                  frames = self.rescale_list(frames, self.seq_length)\n","\n","                  # Build the image sequence\n","                  sequence = self.build_image_sequence(frames)\n","              else:\n","                  # Get the sequence from disk.\n","                  sequence = self.get_extracted_sequence(data_type, sample)\n","\n","                  if sequence is None:\n","                      raise ValueError(\"Can't find sequence. Did you generate them?\")\n","\n","                  X.append(sequence)\n","                  y.append(self.get_class_one_hot(sample[1]))\n","\n","              yield np.array(X), np.array(y)\n","          "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbrop_wMGNUz","colab_type":"code","colab":{}},"source":["class ResearchModels():\n","    def __init__(self, nb_classes, model, seq_length,\n","                 saved_model=None, features_length=2048):\n","        \"\"\"\n","        `model` = mlp\n","        `nb_classes` = the number of classes to predict\n","        `seq_length` = the length of our video sequences\n","        `saved_model` = the path to a saved Keras model to load\n","        \"\"\"\n","\n","        # Set defaults.\n","        self.seq_length = seq_length\n","        self.load_model = load_model\n","        self.saved_model = saved_model\n","        self.nb_classes = nb_classes\n","        self.feature_queue = deque()\n","\n","        # Set the metrics. Only use top k if there's a need.\n","        metrics = ['accuracy']\n","        if self.nb_classes >= 10:\n","            metrics.append('top_k_categorical_accuracy')\n","\n","        # Get the appropriate model.\n","        if self.saved_model is not None:\n","            print(\"Loading model %s\" % self.saved_model)\n","            self.model = load_model(self.saved_model)\n","        elif model == 'lstm':\n","            print(\"Loading LSTM model.\")\n","            self.input_shape = (seq_length, features_length)\n","            self.model = self.lstm()\n","        elif model == 'mlp':\n","            print(\"Loading simple MLP.\")\n","            self.input_shape = (seq_length, features_length)\n","            self.model = self.mlp()\n","        else:\n","            print(\"Unknown network.\")\n","            sys.exit()\n","\n","        # Now compile the network.\n","        optimizer = Adam(lr=1e-5, decay=1e-6)\n","        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n","                           metrics=metrics)\n","\n","        print(self.model.summary())\n","\n","    \n","    \n","    def mlp(self):\n","        \"\"\"Build a simple MLP. It uses extracted features as the input\n","        because of the otherwise too-high dimensionality.\"\"\"\n","        # Model.\n","        model = Sequential()\n","        model.add(Flatten(input_shape=self.input_shape))\n","        model.add(Dense(512))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(512))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(self.nb_classes, activation='softmax'))\n","\n","        return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PN66UGP9GNZl","colab_type":"code","colab":{}},"source":["\n","def train(data_type, seq_length, model, saved_model=None,\n","          class_limit=None, image_shape=None,\n","          load_to_memory=False, batch_size=32, nb_epoch=10):\n","    # Helper: Save the model.\n","    checkpointer = ModelCheckpoint(\n","        filepath=os.path.join(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/\", 'models', model + '-' + data_type + \\\n","            '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n","        verbose=1,\n","        save_best_only=True)\n","\n","    # Helper: TensorBoard\n","    tb = TensorBoard(log_dir=os.path.join(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/\",  'meta', model))\n","\n","    # Helper: Stop when we stop learning.\n","    early_stopper = EarlyStopping(patience=5)\n","\n","    # Helper: Save results.\n","    timestamp = time.time()\n","    csv_logger = CSVLogger(os.path.join(\"gdrive/My Drive/ADBI_Capstone_Video_Classification/data/\" , 'meta', model + '-' + 'training-' + \\\n","        str(timestamp) + '.log'))\n","\n","    # Get the data and process it.\n","    if image_shape is None:\n","        data = DataSet(\n","            seq_length=seq_length,\n","            class_limit=class_limit\n","        )\n","    else:\n","        data = DataSet(\n","            seq_length=seq_length,\n","            class_limit=class_limit,\n","            image_shape=image_shape\n","        )\n","\n","    # Get samples per epoch.\n","    # Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n","    steps_per_epoch = int( (len(data.data) * 0.7) // batch_size )\n","\n","    if load_to_memory:\n","        # Get data.\n","        X, y = data.get_all_sequences_in_memory('train', data_type)\n","        X_test, y_test = data.get_all_sequences_in_memory('test', data_type)\n","    else:\n","        # Get generators.\n","        generator = data.frame_generator(batch_size, 'train', data_type)\n","        val_generator = data.frame_generator(batch_size, 'test', data_type)\n","\n","    # Get the model.\n","    rm = ResearchModels(len(data.classes), model, seq_length, saved_model)\n","\n","    # Fit!\n","    if load_to_memory:\n","        # Use standard fit.\n","        rm.model.fit(\n","            X,\n","            y,\n","            batch_size=batch_size,\n","            validation_data=(X_test, y_test),\n","            verbose=1,\n","            callbacks=[tb, early_stopper, csv_logger],\n","            epochs=nb_epoch)\n","    else:\n","        # Use fit generator.\n","        rm.model.fit_generator(\n","            generator=generator,\n","            steps_per_epoch=steps_per_epoch,\n","            epochs=nb_epoch,\n","            verbose=1,\n","            callbacks=[tb, early_stopper, csv_logger, checkpointer],\n","            validation_data=val_generator,\n","            validation_steps=40,\n","            workers=4)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k3TZXNcGGNeB","colab_type":"code","colab":{}},"source":["def main():\n","    \"\"\"These are the main training settings. Set each before running\n","    this file.\"\"\"\n","    # model can be one of lstm, lrcn, mlp, conv_3d, c3d\n","    model = 'mlp'\n","    saved_model = None  # None or weights file\n","    class_limit = None  # int, can be 1-101 or None\n","    seq_length = 40\n","    load_to_memory = False  # pre-load the sequences into memory\n","    batch_size = 32\n","    nb_epoch = 10\n","    \n","\n","    # Chose images or features and image shape based on network.\n","    if model in ['lstm', 'mlp']:\n","        data_type = 'features'\n","        image_shape = None\n","    else:\n","        raise ValueError(\"Invalid model. See train.py for options.\")\n","\n","    train(data_type, seq_length, model, saved_model=saved_model,\n","          class_limit=class_limit, image_shape=image_shape,\n","          load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SK6qOOFwGNig","colab_type":"code","colab":{}},"source":["\n","if __name__ == '__main__':\n","    main()"],"execution_count":0,"outputs":[]}]}